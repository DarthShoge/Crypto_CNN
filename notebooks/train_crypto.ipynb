{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = False\n",
    "use_ramdon_split = False\n",
    "use_dataparallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "if use_gpu:\n",
    "    from utils.gpu_tools import *\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join([ str(obj) for obj in select_gpu(query_gpu())])\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "IMAGE_WIDTH = {5: 15, 16:64, 20: 60, 60: 180}\n",
    "IMAGE_HEIGHT = {5: 32, 16:48, 20: 64, 60: 96}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data\n",
    "\n",
    "here we choose 1993-2001 data as our training(include validation) data, the remaining will be used in testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156425, 48, 64)\n",
      "(156425, 7)\n"
     ]
    }
   ],
   "source": [
    "raw_images = []\n",
    "raw_label_df = []\n",
    "raw_images = pickle.load(open('../crypto/data/240_16_8_images.dat', 'rb'))\n",
    "raw_label_df = pd.read_feather('../crypto/data/240_16_8_labels.feather')\n",
    "raw_images = np.array(raw_images).reshape((-1, IMAGE_HEIGHT[16], IMAGE_WIDTH[16]))\n",
    "\n",
    "\n",
    "\n",
    "print(raw_images.shape)\n",
    "print(raw_label_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101676, 48, 64)\n",
      "(101676, 7)\n",
      "      Asset          Start_Date            End_Date  Daily_Return   Ret_24H  \\\n",
      "29314   BTC 2013-10-16 21:00:00 2013-10-17 20:00:00      0.024734  0.018115   \n",
      "29315   BTC 2013-10-17 21:00:00 2013-10-18 20:00:00      0.034178  0.036533   \n",
      "29316   BTC 2013-10-18 21:00:00 2013-10-19 20:00:00      0.099098  0.075556   \n",
      "29317   BTC 2013-10-19 21:00:00 2013-10-20 20:00:00     -0.000116 -0.000117   \n",
      "29318   BTC 2013-10-20 21:00:00 2013-10-21 20:00:00      0.083886  0.081870   \n",
      "\n",
      "             Ret_8H    Market_Cap  \n",
      "29314 -6.458785e-03  1.702245e+09  \n",
      "29315  4.096767e-03  1.732996e+09  \n",
      "29316 -2.842424e-02  1.795176e+09  \n",
      "29317 -6.135681e-07  2.023532e+09  \n",
      "29318  2.043606e-02  2.042262e+09  \n",
      "        Asset          Start_Date            End_Date  Daily_Return   Ret_24H  \\\n",
      "47481     ENS 2022-12-19 15:00:00 2022-12-20 14:00:00     -0.029085 -0.036784   \n",
      "135613    SYN 2022-12-19 15:00:00 2022-12-20 14:00:00     -0.039784 -0.054178   \n",
      "110451    PHA 2022-12-19 15:00:00 2022-12-20 14:00:00     -0.036697 -0.046706   \n",
      "89716    LUNA 2022-12-19 15:00:00 2022-12-20 14:00:00     -0.010584 -0.001971   \n",
      "92118   MATIC 2022-12-19 15:00:00 2022-12-20 14:00:00      0.019043  0.018916   \n",
      "\n",
      "          Ret_8H    Market_Cap  \n",
      "47481  -0.007936  3.000344e+08  \n",
      "135613 -0.014905  9.009885e+07  \n",
      "110451 -0.006073  5.616968e+07  \n",
      "89716   0.012700  2.369040e+08  \n",
      "92118   0.003775  7.318051e+09  \n"
     ]
    }
   ],
   "source": [
    "# Calculate the index for 65% of the data\n",
    "split_index = int(0.65 * len(raw_images))\n",
    "\n",
    "# Split the images\n",
    "images = raw_images[:split_index]\n",
    "label_df = raw_label_df.iloc[:split_index]\n",
    "# Split the labels\n",
    "print(images.shape)\n",
    "print(label_df.shape)\n",
    "print(label_df.head())\n",
    "print(label_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img, label):\n",
    "        self.img = torch.Tensor(img.copy())\n",
    "        self.label = torch.Tensor(label)\n",
    "        self.len = len(img)\n",
    "\n",
    "        # Ensure the image tensor is in the shape [batch, height, width]\n",
    "        if len(self.img.shape) == 3:\n",
    "            # Add a channel dimension: [batch, 1, height, width]\n",
    "            self.img = self.img.unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.img[idx], self.label[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split method (not random split is recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_ramdon_split:\n",
    "    train_val_ratio = 0.7\n",
    "    split_idx = int(images.shape[0] * 0.7)\n",
    "    train_dataset = MyDataset(images[:split_idx], (label_df.Ret_24H > 0).values[:split_idx])\n",
    "    val_dataset = MyDataset(images[split_idx:], (label_df.Ret_24H > 0).values[split_idx:])\n",
    "else:\n",
    "    dataset = MyDataset(images, (label_df.Ret_24H > 0).values)\n",
    "    train_val_ratio = 0.7\n",
    "    train_dataset, val_dataset = random_split(dataset, \\\n",
    "        [int(dataset.len*train_val_ratio), dataset.len-int(dataset.len*train_val_ratio)], \\\n",
    "        generator=torch.Generator().manual_seed(42))\n",
    "    del dataset\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 48, 64])\n"
     ]
    }
   ],
   "source": [
    "sample_input, _ = next(iter(train_dataloader))\n",
    "print(sample_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import baseline\n",
    "\n",
    "device = 'cuda' if use_gpu else 'cpu'\n",
    "export_onnx = True\n",
    "net = baseline.Net2(48,64).to(device)\n",
    "net.apply(init_weights)\n",
    "\n",
    "if export_onnx:\n",
    "    import torch.onnx\n",
    "    x = torch.randn([1,1,48,64]).to(device)\n",
    "    torch.onnx.export(net,               # model being run\n",
    "                      x,                         # model input (or a tuple for multiple inputs)\n",
    "                      \"../cnn_baseline.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                      export_params=False,        # store the trained parameter weights inside the model file\n",
    "                      opset_version=10,          # the ONNX version to export the model to\n",
    "                      do_constant_folding=False,  # whether to execute constant folding for optimization\n",
    "                      input_names = ['input_images'],   # the model's input names\n",
    "                      output_names = ['output_prob'], # the model's output names\n",
    "                      dynamic_axes={'input_images' : {0 : 'batch_size'},    # variable length axes\n",
    "                                     'output_prob' : {0 : 'batch_size'}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.0.weight : torch.Size([64, 1, 5, 3])\n",
      "layer1.0.bias : torch.Size([64])\n",
      "layer1.1.weight : torch.Size([64])\n",
      "layer1.1.bias : torch.Size([64])\n",
      "layer2.0.weight : torch.Size([128, 64, 5, 3])\n",
      "layer2.0.bias : torch.Size([128])\n",
      "layer2.1.weight : torch.Size([128])\n",
      "layer2.1.bias : torch.Size([128])\n",
      "layer3.0.weight : torch.Size([256, 128, 5, 3])\n",
      "layer3.0.bias : torch.Size([256])\n",
      "layer3.1.weight : torch.Size([256])\n",
      "layer3.1.bias : torch.Size([256])\n",
      "fc1.1.weight : torch.Size([2, 49152])\n",
      "fc1.1.bias : torch.Size([2])\n",
      "total_parameters : 715010\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for name, parameters in net.named_parameters():\n",
    "    print(name, ':', parameters.size())\n",
    "    count += parameters.numel()\n",
    "print('total_parameters : {}'.format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
      "[INFO] Register count_relu() for <class 'torch.nn.modules.activation.LeakyReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "FLOPs = 37.573623808G\n",
      "Params = 0.71501M\n"
     ]
    }
   ],
   "source": [
    "from thop import profile as thop_profile\n",
    "\n",
    "flops, params = thop_profile(net, inputs=(next(iter(train_dataloader))[0].to(device),))\n",
    "print('FLOPs = ' + str(flops/1000**3) + 'G')\n",
    "print('Params = ' + str(params/1000**2) + 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Code\\DigitalAssets\\liquid-vision\\venv\\lib\\site-packages\\torch\\autograd\\profiler.py:255: UserWarning: CUDA is not available, disabling CUDA profiling\n",
      "  warn(\"CUDA is not available, disabling CUDA profiling\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                  model_inference         0.40%       1.669ms       100.00%     414.743ms     414.743ms             1  \n",
      "                     aten::conv2d         0.01%      21.000us        69.46%     288.082ms      96.027ms             3  \n",
      "                aten::convolution         0.03%     107.000us        69.46%     288.061ms      96.020ms             3  \n",
      "               aten::_convolution         0.01%      49.000us        69.43%     287.954ms      95.985ms             3  \n",
      "         aten::mkldnn_convolution        69.33%     287.553ms        69.42%     287.905ms      95.968ms             3  \n",
      "                      aten::empty         0.14%     582.000us         0.14%     582.000us      18.188us            32  \n",
      "                aten::as_strided_         0.01%      29.000us         0.01%      29.000us       9.667us             3  \n",
      "                    aten::resize_         0.00%       7.000us         0.00%       7.000us       2.333us             3  \n",
      "                       aten::add_         0.01%      53.000us         0.01%      53.000us      17.667us             3  \n",
      "                 aten::batch_norm         0.00%      19.000us         8.74%      36.247ms      12.082ms             3  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 414.743ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "inputs = next(iter(train_dataloader))[0].to(device)\n",
    "\n",
    "with profile(activities=[\n",
    "        ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        net(inputs)\n",
    "\n",
    "prof.export_chrome_trace(\"../trace.json\")\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, net, loss_fn, optimizer):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    current = 0\n",
    "    net.train()\n",
    "    \n",
    "    with tqdm(dataloader) as t:\n",
    "        for batch, (X, y) in enumerate(t):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = net(X)\n",
    "            loss = loss_fn(y_pred, y.long())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss = (len(X) * loss.item() + running_loss * current) / (len(X) + current)\n",
    "            current += len(X)\n",
    "            t.set_postfix({'running_loss':running_loss})\n",
    "    \n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loop(dataloader, net, loss_fn):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    current = 0\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with tqdm(dataloader) as t:\n",
    "            for batch, (X, y) in enumerate(t):\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "                y_pred = net(X)\n",
    "                loss = loss_fn(y_pred, y.long())\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                running_loss = (len(X) * running_loss + loss.item() * current) / (len(X) + current)\n",
    "                current += len(X)\n",
    "            \n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = torch.load('/home/clidg/proj_2/pt/baseline_epoch_10_train_0.6865865240322523_eval_0.686580_.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu and use_dataparallel and 'DataParallel' not in str(type(net)):\n",
    "    net = net.to(device)\n",
    "    net = nn.DataParallel(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-5)\n",
    "\n",
    "start_epoch = 0\n",
    "min_val_loss = 1e9\n",
    "last_min_ind = -1\n",
    "early_stopping_epoch = 5\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "tb = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [08:59<00:00,  1.03it/s, running_loss=0.783]\n",
      "100%|██████████| 120/120 [01:16<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [08:59<00:00,  1.03it/s, running_loss=0.678]\n",
      "100%|██████████| 120/120 [01:14<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [08:34<00:00,  1.08it/s, running_loss=0.625]\n",
      "100%|██████████| 120/120 [01:05<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:47<00:00,  1.19it/s, running_loss=0.594]\n",
      "100%|██████████| 120/120 [01:05<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:50<00:00,  1.18it/s, running_loss=0.571]\n",
      "100%|██████████| 120/120 [01:05<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:45<00:00,  1.20it/s, running_loss=0.551]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:46<00:00,  1.19it/s, running_loss=0.538]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:36<00:00,  1.22it/s, running_loss=0.527]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:38<00:00,  1.22it/s, running_loss=0.521]\n",
      "100%|██████████| 120/120 [01:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:38<00:00,  1.21it/s, running_loss=0.511]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:35<00:00,  1.22it/s, running_loss=0.503]\n",
      "100%|██████████| 120/120 [01:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:37<00:00,  1.22it/s, running_loss=0.499]\n",
      "100%|██████████| 120/120 [01:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:37<00:00,  1.22it/s, running_loss=0.493]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:37<00:00,  1.22it/s, running_loss=0.485]\n",
      "100%|██████████| 120/120 [01:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:35<00:00,  1.22it/s, running_loss=0.483]\n",
      "100%|██████████| 120/120 [01:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:38<00:00,  1.22it/s, running_loss=0.477]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:38<00:00,  1.22it/s, running_loss=0.472]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:37<00:00,  1.22it/s, running_loss=0.47] \n",
      "100%|██████████| 120/120 [01:04<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:38<00:00,  1.21it/s, running_loss=0.467]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:38<00:00,  1.22it/s, running_loss=0.459]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:37<00:00,  1.22it/s, running_loss=0.457]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:37<00:00,  1.22it/s, running_loss=0.452]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:37<00:00,  1.22it/s, running_loss=0.448]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:37<00:00,  1.22it/s, running_loss=0.445]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:38<00:00,  1.22it/s, running_loss=0.44] \n",
      "100%|██████████| 120/120 [01:04<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:39<00:00,  1.21it/s, running_loss=0.435]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:35<00:00,  1.22it/s, running_loss=0.433]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:34<00:00,  1.22it/s, running_loss=0.43] \n",
      "100%|██████████| 120/120 [01:03<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:35<00:00,  1.22it/s, running_loss=0.425]\n",
      "100%|██████████| 120/120 [01:03<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:34<00:00,  1.23it/s, running_loss=0.42] \n",
      "100%|██████████| 120/120 [01:04<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:35<00:00,  1.22it/s, running_loss=0.418]\n",
      "100%|██████████| 120/120 [01:03<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:36<00:00,  1.22it/s, running_loss=0.413]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:38<00:00,  1.22it/s, running_loss=0.41] \n",
      "100%|██████████| 120/120 [01:04<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33\n",
      "-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [07:35<00:00,  1.22it/s, running_loss=0.406]\n",
      "100%|██████████| 120/120 [01:04<00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Best epoch: 28, val_loss: 0.5040865683511881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "os.mkdir('../pt'+os.sep+start_time)\n",
    "epochs = 100\n",
    "for t in range(start_epoch, epochs):\n",
    "    print(f\"Epoch {t}\\n-------------------------------\")\n",
    "    time.sleep(0.2)\n",
    "    train_loss = train_loop(train_dataloader, net, loss_fn, optimizer)\n",
    "    val_loss = val_loop(val_dataloader, net, loss_fn)\n",
    "    tb.add_histogram(\"train_loss\", train_loss, t)\n",
    "    torch.save(net, '../pt'+os.sep+start_time+os.sep+'baseline_epoch_{}_train_{:5f}_val_{:5f}.pt'.format(t, train_loss, val_loss)) \n",
    "    if val_loss < min_val_loss:\n",
    "        last_min_ind = t\n",
    "        min_val_loss = val_loss\n",
    "    elif t - last_min_ind >= early_stopping_epoch:\n",
    "        break\n",
    "\n",
    "print('Done!')\n",
    "print('Best epoch: {}, val_loss: {}'.format(last_min_ind, min_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
